# -*- coding: utf-8 -*-
"""1D - UNET .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-OVL7bO67ue_oyj5fcNdNrENFm-Ds8Ib
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow
!pip install keras
!pip install segmentation_models

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
# %env SM_FRAMEWORK=tf.keras
import glob
import cv2
import os
import numpy as np
from matplotlib import pyplot  as plt
import keras
import pandas as pd
from datetime import datetime
from keras.utils import normalize
import segmentation_models as sm
import random

# Resizing images is optional, CNNs are okay with large images
SIZE_X = 256
SIZE_Y = 256
n_classes = 3

# main_dir = "/Users/anjulo/mig/mri_segmentation/Labeled_Images_Combined"
# main_dir = "/Users/anjulo/mig/mri_segmentation/Cropped_images"
target_dir = "/content/drive/MyDrive/MRI - Research /Labeled MRI DataSet/tail/tail/masks"
feature_dir = "/content/drive/MyDrive/MRI - Research /Labeled MRI DataSet/tail/tail/originals"
dirs = [target_dir, feature_dir]

# Optional: Load test images

#test_images_exclusive = []
#for directory_path in glob.glob(original_dir):
#    for img_path in glob.glob(os.path.join(directory_path, "*.png")):
#        img = cv2.imread(img_path, 1)
#        img = cv2.resize(img, (SIZE_Y, SIZE_X))

#        test_images_exclusive.append(img)

#test_images_exclusive = np.array(test_images_exclusive)
#print(len(test_images_exclusive))

#Code Snipet to display the orignal size and resized size of train images

train_images = []
for dir in dirs:
    count = 0
    for img_path in glob.glob(os.path.join(dir, "*.png")):
        #Load the original image
        original_img = cv2.imread(img_path, 1)

        #Print the original size
        print(f"Original size of {img_path}: {original_img.shape}")

        #Resize the image
        resized_img = cv2.resize(original_img, (SIZE_X, SIZE_Y))

        #Print the resized size
        print(f"Resized size of {img_path}: {resized_img.shape}")

        #train_images.append(resized_img)
        count += 1

    print(dir.split('/')[-1], "has", count, "files")

#Convert the list of images to a NumPy array
train_images = np.array(train_images)

print(train_images.shape)

# Load training images
# train_images = []

# Get a list of subfolders in sorted order
# subfolders = sorted([f for f in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, f))])

# Iterate through each subfolder and append images
# for subfolder in subfolders:
#     subfolder_path = os.path.join(main_dir, subfolder, "JPEGImages")
#     # Get a list of image files in sorted order
#     img_paths = sorted(glob.glob(os.path.join(subfolder_path, "*.jpg")))
#     for img_path in img_paths:
#         img = cv2.imread(img_path, 1)
#         img = cv2.resize(img, (SIZE_Y, SIZE_X))
#         train_images.append(img)

train_images = []

# for img_path in glob.glob(os.path.join(feature_dir, "*.png")):
#       count = 0
#       img = cv2.imread(img_path, 1)
#       img = cv2.resize(img, (SIZE_Y, SIZE_X))
#       train_images.append(img)
#       count += 1
print(dir.split('/')[-1], "has", count, "files" )

# Convert the list of images to a NumPy array
train_images = np.array(train_images)

print(train_images.shape)

def preprocess_mask(mask):
    # Calculate the histogram
    hist = cv2.calcHist([mask], [0], None, [256], [0, 256])

    # Sort the histogram in descending order
    sorted_hist = sorted(enumerate(hist), key=lambda x: x[1], reverse=True)

    # Get the top three dominant values (excluding background value)
    dominant_values = [int(sorted_hist[i][0]) for i in range(3)] #  if int(sorted_hist[i][0]) != 0
    # print(dominant_values)
    # Create a new matrix for the processed image
    processed_mask = mask.copy()

    # Iterate through the mask matrix and replace non-dominant values
    for i in range(processed_mask.shape[0]):
        for j in range(processed_mask.shape[1]):
            pixel_value = int(processed_mask[i, j])
            if pixel_value not in dominant_values:
                # Find the closest dominant value
                closest_dominant = min(dominant_values, key=lambda x: abs(x - pixel_value))
                processed_mask[i, j] = closest_dominant

    return processed_mask

# # Example usage:
# # Load your grayscale image into a NumPy array (matrix)
# input_mask_matrix = cv2.imread('mask_image.png', cv2.IMREAD_GRAYSCALE)

# # Call the function to preprocess the matrix
# processed_matrix = preprocess_mask(input_mask_matrix)


#Capture mask/label info as a list
# train_masks = []

# Get a list of subfolders in sorted order
# subfolders = sorted([f for f in os.listdir(main_dir) if os.path.isdir(os.path.join(main_dir, f))])

# Iterate through each subfolder and append images
# for subfolder in subfolders:
#     subfolder_path = os.path.join(main_dir, subfolder, "SegmentationClass")
#     # Get a list of image files in sorted order
#     mask_paths = sorted(glob.glob(os.path.join(subfolder_path, "*.png")))
#     for mask_path in mask_paths:
#         mask = cv2.imread(mask_path, 0) # 0 = grayscale
#         mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)
#         train_masks.append(mask)

train_masks = []

for mask_path in glob.glob(os.path.join(target_dir, "*.png")):
      count=0
      mask = cv2.imread(mask_path, 0) # 0 = grayscale
      mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)
      mask = preprocess_mask(mask)
      train_masks.append(mask)
      count += 1
print(dir.split('/')[-1], "has", count, "files" )

# Convert the list of images to a NumPy array
train_masks = np.array(train_masks)

print(np.unique(train_masks))
print(train_masks.shape)

# Choose a random index
random_index = random.randint(0, len(train_masks) - 1)
print(len(train_masks), random_index)
# Get the random mask image
random_mask = train_masks[random_index]

# Display the random mask image
plt.imshow(mask, cmap='gray')
plt.title("Random Mask Image")
plt.axis('off')  # Hide axes
plt.show()

# doing the below as masks are colored and not grayscale
# Encode labels/one hot encoding... but multi dim array so need to flatten, encode and reshape

from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
n, h, w = train_masks.shape # print(n, h, w) # the dimensions of the np array # len_train_images * SIZE_X * SIZE_Y
train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks.flatten())
train_masks_encoded = train_masks_reshaped_encoded.reshape(n, h, w)

print("Unique values in the encoded train masks", np.unique(train_masks_encoded))

#train_images = np.expand_dims(train_images, axis=3)
#train_images = normalize(train_images, axis=1)

# prepare input for Unet by adding one more dimension
train_masks_input = np.expand_dims(train_masks_encoded, axis=3)
print(train_masks_input.shape)

#Create a subset of data for quick testing
#Picking 10% for testing and remaining for training
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)
print(X_train.shape, X_test.shape)
print(y_train.shape, y_test.shape)

#Further split training data t a smaller subset for quick testing of models
#X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.5, random_state = 0


print("Class values in the dataset are ... ", np.unique(y_train))  # 0 is the background/few unlabeled

# essentially one-hot encoding for classes in the mask
from keras.utils import to_categorical
n_classes = 3
train_masks_cat = to_categorical(y_train, num_classes=n_classes) # output is of shape (samples, height, width, classes)
print(train_masks_cat.shape)  # (samples, height, width, classes)
y_train_cat = train_masks_cat #.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))

test_masks_cat = to_categorical(y_test, num_classes=n_classes)
print(test_masks_cat.shape)
y_test_cat = test_masks_cat #.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))

LR = 0.0001
optim = keras.optimizers.legacy.Adam(LR)
# optim = keras.optimizers.Adam(LR)

# Segmentation models losses can be combined together by '+' and scaled by integer or float factor
# set class weights for dice_loss
# dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.12, 0.22, 0.22, 0.22, 0.22]))
# focal_loss = sm.losses.CategoricalFocalLoss() #
# total_loss = dice_loss + (1 * focal_loss)
total_loss = sm.losses.categorical_focal_dice_loss # or sm.losses.categorical_focal_loss
# total_loss = focal_loss

# actulally total_loss can be imported directly from library, above example just shows how to manipulate with losses
# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss

metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]

################
# Can experiment with multiple backbones, found this the best so far
BACKBONE1 = 'resnet34'
#BACKBONE1 = 'efficientnetb0'
preprocess_input1 = sm.get_preprocessing(BACKBONE1)

# preprocess input
X_train1 = preprocess_input1(X_train)
X_test1 = preprocess_input1(X_test)

model1 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_classes, activation='softmax')

print(X_train1.shape)
print(y_train_cat.shape)
upsampled_output = model1.get_layer('decoder_stage0_upsampling').output
relu_output = model1.get_layer('stage4_unit1_relu1').output

print(upsampled_output.shape)
print(relu_output.shape)

#######################

model1 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_classes, activation='softmax')

# compile keras model with defined optimizer, loss and metrics
model1.compile(optim, total_loss, metrics=metrics)
#model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics, encoder_freeze=True)
#model.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])
#model.compile('Adam', loss=sm.losses.CategoricalFocalLoss(), metrics=[sm.metrics.iou_score])

#print(model1.summary())

# fit model

history1=model1.fit(
          X_train1,
          y_train_cat,
          batch_size=2,
          epochs=15,
          verbose=1,
          validation_data=(X_test1, y_test_cat))

model1.save('unet_segmentation_model_lib_cropped_150_named.hdf50')

# convert the history.history dict to a pandas DataFrame:
hist1_df = pd.DataFrame(history1.history)
hist1_csv_file = 'history_unet.csv'
with open(hist1_csv_file, mode='w') as f:
    hist1_df.to_csv(f)

##########################################################
# ###
# #plot the training and validation accuracy and loss at each epoch
# loss = history1.history['loss']
# val_loss = history1.history['val_loss']
# epochs = range(1, len(loss) + 1)
# plt.plot(epochs, loss, 'y', label='Training loss')
# plt.plot(epochs, val_loss, 'r', label='Validation loss')
# plt.title('Training and validation loss')
# plt.xlabel('Epochs')
# plt.ylabel('Loss')
# plt.legend()
# plt.show()

# acc = history1.history['iou_score']
# val_acc = history1.history['val_iou_score']

# plt.plot(epochs, acc, 'y', label='Training IOU')
# plt.plot(epochs, val_acc, 'r', label='Validation IOU')
# plt.title('Training and validation IOU')
# plt.xlabel('Epochs')
# plt.ylabel('IOU')
# plt.legend()
# plt.show()

# Plot the training and validation accuracy and loss at each epoch
loss = history1.history['loss']
val_loss = history1.history['val_loss']
acc = history1.history['iou_score']
val_acc = history1.history['val_iou_score']
epochs = range(1, len(loss) + 1)

# Create a figure with two subplots side by side
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Plot training and validation loss in the first subplot
axes[0].plot(epochs, loss, 'y', label='Training loss')
axes[0].plot(epochs, val_loss, 'r', label='test loss')
axes[0].set_title('Training and validation loss')
axes[0].set_xlabel('Epochs')
axes[0].set_ylabel('Loss')
axes[0].legend()

# Plot training and validation IOU in the second subplot
axes[1].plot(epochs, acc, 'y', label='Training IOU')
axes[1].plot(epochs, val_acc, 'r', label='test IOU')
axes[1].set_title('Training and test IOU')
axes[1].set_xlabel('Epochs')
axes[1].set_ylabel('IOU')
axes[1].legend()

# Display the subplots
plt.show()

# class_labels = {
#     0: 'Background',
#     1: 'BoneMarrow',
#     2: 'Tibia',
#     3: 'Fibula',
#     4: 'Femur'
# }

class_labels = {
    0: 'Background',
    1: 'Bone',
    2: 'BoneMarrow'
}

# class_labels = {
#     0: 'Background',
#     1: 'Bone',
#     2: 'Muscle',
#     3: 'Ligament'
# }


# use class labels according to the prediction task at hand
#####################################################

from keras.models import load_model

# compile=False as we are not loading it for training but for prediction.
model_unet = load_model('unet_segmentation_model_lib_cropped_150_named.hdf50', compile=False)

#FOR DJL TESTING (Viz. team test)
#tf.saved_model.save(model_unet, "test")

# IOU
y_pred_unet=model_unet.predict(X_test1)
y_pred_unet_argmax=np.argmax(y_pred_unet, axis=3)

# From built in keras function
from keras.metrics import MeanIoU
n_classes = 3

IOU_unet = MeanIoU(num_classes=n_classes)
IOU_unet.update_state(y_test[:,:,:,0], y_pred_unet_argmax)

print("Mean IoU using Unet =", IOU_unet.result().numpy())

import random
test_img_number = random.randint(0, len(X_test1) - 1)
# test_img_number = 6
test_img = X_test1[test_img_number]
ground_truth=y_test[test_img_number]
test_img_input=np.expand_dims(test_img, 0)
test_img_input1 = preprocess_input1(test_img_input)

test_pred_unet = model_unet.predict(test_img_input1)
test_prediction_unet = np.argmax(test_pred_unet, axis=3)[0,:,:]

# Calculation of IOU
y_pred=model1.predict(X_test)
y_pred_argmax=np.argmax(y_pred, axis=3)

from keras.metrics import MeanIoU
n_classes = 5
IOU_keras = MeanIoU(num_classes=n_classes)
IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)

mean_IOU = IOU_keras.result().numpy()
print("Mean IoU =", mean_IOU)

# calculate I0U for each class
values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)
print(values)
class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[1,0]+ values[2,0])
class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[0,1]+ values[2,1])
class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[0,2]+ values[1,2])

#class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])
#class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])
#class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])
#class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])


# plt.figure(figsize=(12, 10))
# #plt.figure(figsize=(12, 8))
# plt.subplot(231)
# plt.title('Testing Image')
# plt.imshow(test_img[:,:,0], cmap='gray')

# plt.subplot(232)
# plt.title('Testing Label (Ground Truth)')

# # Plot the image with a color map
# im = plt.imshow(ground_truth[:,:,0], cmap='jet')

# # Get unique values in the image
# unique_vals_legend = np.unique(ground_truth)

# # Create a color map for the legend
# colors = [im.cmap(im.norm(value)) for value in unique_vals_legend]
# patches = [plt.Rectangle((0,0),1,1, color=colors[i]) for i in range(len(unique_vals_legend))]

# # Add a legend with the unique values, their corresponding colors, and class labels
# labels = [class_labels[value] for value in unique_vals_legend]
# plt.legend(patches, labels, loc='lower center', bbox_to_anchor=(0.5, -0.3), ncol=5)

# plt.subplot(233)
# plt.title('Prediction on test image')
# plt.imshow(test_prediction_unet, cmap='jet')

# plt.subplot(234)
# plt.title('Overlay of orig & pred')
# plt.imshow(test_img[:,:,0], cmap='gray')
# plt.imshow(test_prediction_unet, cmap='jet', alpha=0.6)

# # print IOU values on the output plt
# plt.text(-0.08, -0.5, f'Mean IOU: {mean_IOU}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)

# plt.text(-0.08, -0.6, f'IoU for class1 is (background): {class1_IoU}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)
# plt.text(-0.08, -0.7, f'IoU for class2 is (bone): {class2_IoU}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)
# plt.text(-0.08, -0.8, f'IoU for class3 is (bone_marrow): {class3_IoU}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)
# #plt.text(-0.08, -0.9, f'IoU for class3 is (ligament): {class4_IoU}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes)

# plt.show()

# Create a 2x2 grid of subplots
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Plot the first image in the top-left subplot
axes[0, 0].set_title('Testing Image')
axes[0, 0].imshow(test_img[:,:,0], cmap='gray')

# Plot the label with a legend in the top-right subplot
axes[0, 1].set_title('Testing Label (Ground Truth)')
im = axes[0, 1].imshow(ground_truth[:,:,0], cmap='jet')
unique_vals_legend = np.unique(ground_truth)
colors = [im.cmap(im.norm(value)) for value in unique_vals_legend]
patches = [plt.Rectangle((0,0),1,1, color=colors[i]) for i in range(len(unique_vals_legend))]
labels = [class_labels[value] for value in unique_vals_legend]
axes[0, 1].legend(patches, labels, loc='lower center', bbox_to_anchor=(0.5, -0.3), ncol=5)

# Plot the prediction in the bottom-left subplot
axes[1, 0].set_title('Prediction on test image')
axes[1, 0].imshow(test_prediction_unet, cmap='jet')

# Overlay the original and prediction in the bottom-right subplot
axes[1, 1].set_title('Overlay of orig & pred')
axes[1, 1].imshow(test_img[:,:,0], cmap='gray')
axes[1, 1].imshow(test_prediction_unet, cmap='jet', alpha=0.6)

# Print IOU values on the output plot
axes[1, 1].text(-0.08, -0.5, f'Mean IOU: {mean_IOU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)
axes[1, 1].text(-0.08, -0.6, f'IoU for class1 (background): {class1_IoU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)
axes[1, 1].text(-0.08, -0.7, f'IoU for class2 (bone): {class2_IoU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)
axes[1, 1].text(-0.08, -0.8, f'IoU for class3 (bone_marrow): {class3_IoU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)

# Remove any remaining empty subplot
axes[0, 1].axis('off')

# Display the 2x2 grid
plt.show()

# use class labels according to the prediction task at hand

#####################################################
from keras.models import load_model

# compile=False as we are not loading it for training but for prediction.
model_unet = load_model('unet_segmentation_model_lib_cropped_150_named.hdf50', compile=False)

#FOR DJL TESTING (Viz. team test)
#tf.saved_model.save(model_unet, "test")

# IOU
y_pred_unet=model_unet.predict(X_test1)
y_pred_unet_argmax=np.argmax(y_pred_unet, axis=3)


# From built in keras function
from keras.metrics import MeanIoU
n_classes = 3

# IOU_unet = MeanIoU(num_classes=n_classes)
# IOU_unet.update_state(y_test[:,:,:,0], y_pred_unet_argmax)

# print("Mean IoU using Unet =", IOU_unet.result().numpy())

import random
test_img_number = random.randint(0, len(X_test1) - 1)
print(len(X_test1))
print("image #: ", test_img_number)
# test_img_number = 6
test_img = X_test1[test_img_number]
ground_truth=y_test[test_img_number]
test_img_input=np.expand_dims(test_img, 0)
test_img_input1 = preprocess_input1(test_img_input)

test_pred_unet = model_unet.predict(test_img_input1)
test_prediction_unet = np.argmax(test_pred_unet, axis=3)[0,:,:]

# # Calculation of IOU
# y_pred=model1.predict(X_test)
# y_pred_argmax=np.argmax(y_pred, axis=3)

# from keras.metrics import MeanIoU
# n_classes = 5
# IOU_keras = MeanIoU(num_classes=n_classes)
# IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)

# mean_IOU = IOU_keras.result().numpy()
# print("Mean IoU =", mean_IOU)

# # calculate I0U for each class
# values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)
# print(values)
# class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[1,0]+ values[2,0])
# class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[0,1]+ values[2,1])
# class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[0,2]+ values[1,2])

# Create a 2x2 grid of subplots
fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# Plot the first image in the top-left subplot
axes[0, 0].set_title('Testing Image')
axes[0, 0].imshow(test_img[:,:,0], cmap='gray')

# Plot the label with a legend in the top-right subplot
axes[0, 1].set_title('Testing Label (Ground Truth)')
im = axes[0, 1].imshow(ground_truth[:,:,0], cmap='jet')
unique_vals_legend = np.unique(ground_truth)
colors = [im.cmap(im.norm(value)) for value in unique_vals_legend]
patches = [plt.Rectangle((0,0),1,1, color=colors[i]) for i in range(len(unique_vals_legend))]
labels = [class_labels[value] for value in unique_vals_legend]
axes[0, 1].legend(patches, labels, loc='lower center', bbox_to_anchor=(0.5, -0.3), ncol=5)

# Plot the prediction in the bottom-left subplot
axes[1, 0].set_title('Prediction on test image')
axes[1, 0].imshow(test_prediction_unet, cmap='jet')

# Overlay the original and prediction in the bottom-right subplot
axes[1, 1].set_title('Overlay of orig & pred')
axes[1, 1].imshow(test_img[:,:,0], cmap='gray')
axes[1, 1].imshow(test_prediction_unet, cmap='jet', alpha=0.6)

#Print IOU values on the output plot
axes[1, 1].text(-0.08, -0.5, f'Mean IOU: {mean_IOU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)
axes[1, 1].text(-0.08, -0.6, f'IoU for class1 (background): {class1_IoU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)
axes[1, 1].text(-0.08, -0.7, f'IoU for class2 (bone): {class2_IoU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)
axes[1, 1].text(-0.08, -0.8, f'IoU for class3 (bone_marrow): {class3_IoU}', horizontalalignment='center', verticalalignment='center', transform=axes[1, 1].transAxes)

# Remove any remaining empty subplot
axes[0, 1].axis('off')

# Display the 2x2 grid
plt.show()